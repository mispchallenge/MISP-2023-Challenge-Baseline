model:
  network_name: mease_asr_jo
  network_setting:
    out_channels: 201
    skip_convert: False
    input_types: [ mixture_wave, lip_frames]
    extractor_types: [ lps, multimodal_embedding ]
    extractor_settings:
      - n_fft: 400
        hop_length: 160
        win_type: hamming
        win_length: 400
        cmvn: ./cmvn/cmvn_lps_misp_real_trainset.pt
        requires_grad: False
      - extract_feature: True
        skip_convert: True
        input_types: [ mixture_wave, lip_frames ]
        extractor_types: [ fbank, gray_crop_flip ]
        extractor_settings:
          - n_fft: 400
            hop_length: 160
            win_type: hamming
            win_length: 400
            cmvn: ./cmvn/cmvn_fbank_htk_misp_real_trainset.pt
            f_min: 0
            f_max: 8000
            n_mels: 40
            sample_rate: 16000
            norm: slaney
            preemphasis_coefficient: 0.97
            vtln: False
            vtln_low: 0
            vtln_high: 8000
            vtln_warp_factor: 1.
          - channel_input: bgr
            size: [ 88, 88 ]
            random: False
        frontend_types: [ conv1d, conv3d ]
        frontend_settings:
          - out_channels: 64
            conv1d_kernel: 1
            conv1d_stride: 1
            act_type: prelu
          - out_channels: 64
            conv3d_kernel: [ 5, 7, 7 ]
            conv3d_stride: [ 1, 2, 2 ]
            act_type: prelu
            pool3d_kernel: [ 1, 3, 3 ]
            pool3d_stride: [ 1, 2, 2 ]
        backbone_types: [ resnet1d, resnet2d ]
        backbone_settings:
          - block_type: basic1d
            block_num: 2
            act_type: prelu
            hidden_channels: [ 64, 128, 256, 512 ]
            stride: [ 1, 1, 1, 1 ]
            expansion: 1
            downsample_type: avgpool
          - block_type: basic2d
            block_num: 2
            act_type: prelu
            hidden_channels: [ 64, 128, 256, 512 ]
            stride: [ 1, 2, 2, 2 ]
            expansion: 1
            downsample_type: avgpool
        fuse_type: tcn
        fuse_setting:
          hidden_channels: [ 768, 768, 768, 768 ]
          kernels_size: [ 3, 5, 7 ]
          dropout: 0.2
          act_type: prelu
          dwpw: False
          downsample_type: norm
        requires_grad: False
    encoder_types: [ DSResConv, DSResConv ]
    encoder_settings:
      - layer_num: 5
        out_channels: 1536
        kernel: 5
        stride: [ 1, 1, 1, 1, 1 ]
        dilation: 1
        norm_type: BN1d
        requires_grad: True
      - layer_num: 10
        out_channels: 1536
        kernel: 5
        stride: [ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ]
        dilation: 1
        norm_type: BN1d
        requires_grad: True
    fusion_type: cat
    fusion_setting: { }
    decoder_type: DSResConv
    decoder_setting:
      layer_num: 15
      out_channels: 1536
      kernel: 5
      requires_grad: True
      stride: [ 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 ]
      dilation: 1
      norm_type: BN1d
    reconstruct_settings:
      n_fft: 400
      hop_length: 160
      win_type: hamming
      win_length: 400
      rescale: False
  pretrained_num: 1
  pretrained_model:
    - - ./pretrainModels/mease.tar
      - model_params
  fixed_type: fixed_keys
  fixed_keys:
    - multimodal_embedding_extractor.embedding_extractor.

data:
  loader_output:
    items: &input_items [ mixture_wave, lip_frames, text ] 
    shapes: &input_shapes [ [ 0 ], [ 0, 96, 96, 3 ] ,[ 0 ]]
    pad_values: &input_pad_values [ 0, 0, -1 ]
  model_input:
    items: {'mixture_wave': 0, 'lip_frames': 2, 'text': 4, 'wav_length': 1, 'video_length': 3, 'text_length': 5}
    gpu_items: [mixture_wave, lip_frames, text]
  model_output:
    items: &output_items [predicted_mask]
    store_items: {'predicted_mask': 2}
    store_item2length: {'predicted_mask': 3}
  loss_input:
    gpu_items:
    - clean_wave
    - mixture_wave
    items_from_loader:
      mixture_wave: 0
      clean_wave: 4
      length: 1
    items_from_model:
      net_output: 0

  train:
    annotate:
      #- /yrfs1/intern/cyzhang39/EASE/TCD-TIMIT_sr_16000_fps_25_noisy_35h/train_snr_-10_-5_0_5_10_15.json
      - ../data_prepare/misp_real_trainset.json
    repeat: 1
    max_duration: 100
    hop_duration: 6
    items: *input_items
    dynamic: True
    batch_size: 8
    max_batch_size: 256
    bucket_length_multiplier: 1.2
    shuffle: True
    drop_last: False
    num_workers: 4
    pin_memory: False
    target_shape: *input_shapes
    pad_value: *input_pad_values
  test:
    annotate:
      - ../data_prepare/misp_real_trainset_test.json
    repeat: 1
    max_duration: 100
    hop_duration: 6
    items: *input_items
    dynamic: True
    batch_size: 8
    max_batch_size: 256
    bucket_length_multiplier: 1.2
    shuffle: True
    drop_last: False
    num_workers: 4
    pin_memory: False
    target_shape: *input_shapes
    pad_value: *input_pad_values


optimizer:
  optimizer_type: Adam
  group_num: 1
  force_lr: False
  common_setting:
    lr: 0.00001
    betas: [0.9, 0.999]
    eps: 0.00000001
    weight_decay: 0.0
    amsgrad: False

scheduler:
  scheduler_type: improve
  scheduler_setting:
    factor: 0.5
    patience: 3

loss:
  loss_setting:
    extractor_setting:
      hop_length: 160
      mask_type: irm
      n_fft: 400
      win_length: 400
      win_type: hamming
    mode: error
  loss_type: misp_mse_calcIRMLabel

gradient:
  grad_clip: 5.

reconstruct:
  predict_items: *output_items
  data_items: [ mixture_wave ]
  reconstruct_items: &reconstruct_items [ reconstruct_wave ]
  reconstruct_type: mack2wave
  reconstruct_settings:
    n_fft: 400
    hop_length: 160
    win_type: hamming
    win_length: 400
    rescale: False

#evaluate:
#  degraded_items:
#  target_items:
#  evaluate_items:
#  evaluate_types:
#  evaluate_settings:
#  evaluate_results:

evaluate:
  degraded_items: *reconstruct_items
  target_items:
    - clean_wave
  evaluate_types:
    - pesq
    - stoi
  evaluate_results:
    - - pesq
    - - stoi
  evaluate_settings:
    - fs: 16000
    - fs: 16000
      extended: False
